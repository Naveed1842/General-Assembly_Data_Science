{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn import linear_model\n",
    "import random\n",
    "from sklearn import feature_selection\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's assume here is your actual output\n",
    "y = [1,2,3,4,5]\n",
    "\n",
    "And your prediction is\n",
    "\n",
    "y_predict = [2,2,3,4,5]\n",
    "\n",
    "Your MSE is ((1-2)^2 + (2-2)^2 + ... + (5-5)^2)/5 = 1/5 = .2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Let's find MSE using sklearn \n",
    "\n",
    "y = [1,2,3,4,5]\n",
    "y_predict = [2,2,3,4,5]\n",
    "metrics.mean_squared_error(y,y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Let's generate 300 random numbers between -10 and 10\n",
    "x = np.zeros(300)\n",
    "for i in range(300):\n",
    "   x[i] = random.uniform(-10, 10)\n",
    "\n",
    "#Let's generate some error term with mean 0 and s.d. = 20\n",
    "error = np.random.normal(0,20,300)\n",
    "#Now let's generate y with a polynomial degree 2 relationship with x\n",
    "\n",
    "y = 3 + 1.5 * x + 4 * (x ** 2) + error\n",
    "df = pd.DataFrame({'X': x, 'y': y})\n",
    "\n",
    "df.plot(kind = 'scatter', x = 'X', y = 'y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Now let's add few non-linear terms to our data frame\n",
    "#The 'correct' model will select X and X^2 values\n",
    "df['X_2'] = df.X ** 2\n",
    "df['X_3'] = df.X ** 3\n",
    "df['X_4'] = df.X ** 4\n",
    "df['X_5'] = df.X ** 5\n",
    "\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X1 = df[['X']]\n",
    "X2 = df[['X','X_2']]\n",
    "X3 = df[['X','X_2','X_3']]\n",
    "X4 = df[['X','X_2','X_3','X_4']]\n",
    "X5 = df[['X','X_2','X_3','X_4','X_5']]\n",
    "y = df['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lm = linear_model.LinearRegression()\n",
    "MSE = np.zeros(5)\n",
    "j = 0\n",
    "for i in [X1,X2,X3,X4,X5]:\n",
    "    lm.fit(i,y)\n",
    "    MSE[j] = (metrics.mean_squared_error(lm.predict(i),y))\n",
    "    pvals = feature_selection.f_regression(i,y)[1]\n",
    "    print(pvals)\n",
    "    j += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### in comparison to R, sklearn is using a different method to estimate p-values. P-values in sklearn are not reliable. If you want to use p-values, use statsmodels.formula.api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in [X1,X2,X3,X4,X5]:\n",
    "    lm1 = smf.ols(formula='y ~ i', data=df).fit()\n",
    "    print(lm1.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Based on P-values, it is clear that our models are only valid up to 2 degrees of polynomial. After that coefficients are not statistically significant. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As much as sklearn performs weak for p-values, it is a great tool for splitting data into Training and Test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X1, y, test_size=0.33)\n",
    "#We train based on Training Data BUT will Test on Test Sample\n",
    "Model_train = lm.fit(X_train,y_train)\n",
    "y_Hat_train = lm.predict(X_train)\n",
    "y_Hat_test  = lm.predict(X_test)\n",
    "MSE_Train = metrics.mean_squared_error(y_Hat_train,y_train)\n",
    "MSE_Test  = metrics.mean_squared_error(y_Hat_test,y_test)\n",
    "print(\"MSE_Train =\",MSE_Train)\n",
    "print(\"MSE_Test =\", MSE_Test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, it's time to use Validation techniques to test which model is more significant. Remember we need to train based on training sets but test the performance on test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MSE_test = np.zeros(5)\n",
    "MSE_train = np.zeros(5)\n",
    "j = 0\n",
    "for i in [X1,X2,X3,X4,X5]:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(i, y, test_size=0.33)\n",
    "    lm.fit(X_train,y_train)\n",
    "    MSE_test[j] = (metrics.mean_squared_error(lm.predict(X_test),y_test))\n",
    "    MSE_train[j] = (metrics.mean_squared_error(lm.predict(X_train),y_train))\n",
    "    j += 1\n",
    "\n",
    "index = np.array(range(5)) + 1\n",
    "MSE_Test_df = pd.DataFrame({'MSE_test':MSE_test,'index':index,'MSE_train':MSE_train})\n",
    "print(MSE_Test_df)\n",
    "MSE_Test_df.plot(x = 'index',y= ['MSE_test','MSE_train'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on test-set MSE, we decide to choose Model 2 - polynomial degree 2. Remember ** THE SIMPLER THE BETTER **."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sklearn is great for Cross-Validation. 10 fold and 5 fold cross-validation are the most famous cross-validation techniques. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import cross_validation\n",
    "kf = cross_validation.KFold(len(df), n_folds = 5, shuffle = True) \n",
    "#shuffle=True randomly creates groups rather than keeping them in order\n",
    "#creates a list of tuples\n",
    "\n",
    "#for train_index, test_index in kf:\n",
    "#    print(\"TRAIN:\", train_index, \"TEST:\", test_index) #yields two arrays of indices?\n",
    "\n",
    "scores = []\n",
    "for train_index, test_index in kf:\n",
    "    lm = linear_model.LinearRegression().fit(X2.iloc[train_index], y.iloc[train_index])\n",
    "    scores.append(metrics.mean_squared_error(y.iloc[test_index], lm.predict(X2.iloc[test_index])))\n",
    "\n",
    "print('Raw scores:',scores)\n",
    "print('Mean:',np.mean(scores))\n",
    " \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, let's use cross validation to decide which degree of polynomials is suitable for our simulated model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kf = cross_validation.KFold(len(df), n_folds = 5, shuffle = True) \n",
    "MSE_CV = []\n",
    "\n",
    "for i in [X1,X2,X3,X4,X5]:\n",
    "    scores = []\n",
    "    for train_index, test_index in kf:\n",
    "        lm = linear_model.LinearRegression().fit(i.iloc[train_index], y.iloc[train_index])\n",
    "        scores.append(metrics.mean_squared_error(y.iloc[test_index], lm.predict(i.iloc[test_index])))\n",
    "    MSE_CV.append(np.mean(scores))\n",
    "        \n",
    "        \n",
    "print(MSE_CV)\n",
    "index = np.array(range(5)) + 1\n",
    "MSE_CV_df = pd.DataFrame({'MSE_CV':MSE_CV,'index':index})\n",
    "MSE_CV_df.plot(x = 'index',y= 'MSE_CV')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, 5-fold cross-validation suggests that polynomial degree 2 is our best model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso and Ridge Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use Credit data. We will first add dummy variables and drop original qualitative values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/ga-students/SF-DAT-20/master/Data/Credit.csv\"\n",
    "CreditData = pd.read_csv(url)\n",
    "RaceDummy = pd.get_dummies(CreditData.Ethnicity, prefix = 'Race')\n",
    "del RaceDummy['Race_African American']\n",
    "GenderDummy = pd.get_dummies(CreditData.Gender, prefix = 'Gender')\n",
    "del GenderDummy['Gender_ Male']  \n",
    "MarriedDummy = pd.get_dummies(CreditData.Married, prefix = 'Married')\n",
    "del MarriedDummy['Married_No']\n",
    "StudentDummy = pd.get_dummies(CreditData.Student, prefix = 'Student')\n",
    "del StudentDummy['Student_No']\n",
    "CreditData = pd.concat([CreditData, RaceDummy,GenderDummy,MarriedDummy,StudentDummy], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "del CreditData['Unnamed: 0']\n",
    "del CreditData['Gender']\n",
    "del CreditData['Student']\n",
    "del CreditData['Married']\n",
    "del CreditData['Ethnicity']\n",
    "CreditData.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to divide our dataset - to output y and all inputs X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "listOfAllVariables = CreditData.columns.values\n",
    "print(listOfAllVariables)\n",
    "X = CreditData[listOfAllVariables]\n",
    "del X['Balance']\n",
    "y = CreditData['Balance']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#this was a lasso regression with default values\n",
    "lm_lasso = linear_model.Lasso().fit(X,y)\n",
    "lm_lasso.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to use CV to decide on the optimal level of Alpha - the parameter of Lasso Regressions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kf = cross_validation.KFold(len(CreditData), n_folds = 5, shuffle = True)\n",
    "MSE_Lasso_CV = []\n",
    "alphas = np.logspace(-10, 10, 21) #Getting 21 values between 1*10^-10 to 1*10^10\n",
    "alphas_index = np.linspace(-10,10,21) #Define index as power of ten\n",
    "for a in alphas:\n",
    "    print 'Alpha:', a\n",
    "    scores = []\n",
    "    for train_index, test_index in kf:\n",
    "        lm = linear_model.Lasso(alpha=a).fit(X.iloc[train_index], y.iloc[train_index]) #Creates model with coefficients\n",
    "        scores.append(metrics.mean_squared_error(y.iloc[test_index], lm.predict(X.iloc[test_index])))\n",
    "    MSE_Lasso_CV.append(np.mean(scores))\n",
    "\n",
    "\n",
    "\n",
    "index = alphas\n",
    "MSE_Lasso_CV_df = pd.DataFrame({'MSE_Lasso_CV': MSE_Lasso_CV ,'Log_Alphas': alphas_index })\n",
    "MSE_Lasso_CV_df.plot(x = 'Log_Alphas',y = 'MSE_Lasso_CV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#MSE is flat up to log_alpha = 1. Log_alpha results in alpha = 10 (due to its logarithmic scale)\n",
    "lm = linear_model.Lasso(alpha=10)\n",
    "lm.fit(X, y)\n",
    "print zip(lm.coef_,X.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Based on Lasso regression outputs, we decide to eliminate Gender, Marital Status, Education, and Race from our model. The coefficients that made it to our final models were Income, Limit, Rating (we shall only choose 1 of these three variables due to colinearity), Number of Cards, Age, and Studentship. Based on our previous In-Class-Practice, we were expecting to have Income and Studentship in our model. Now, since we are only left with 4 variables, we can run statistical tests and choose the most significant model. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kf = cross_validation.KFold(len(CreditData), n_folds = 5, shuffle = True)\n",
    "MSE_Ridge_CV = []\n",
    "alphas = np.logspace(-10, 10, 21)\n",
    "alphas_index = np.linspace(-10,10,21)\n",
    "for a in alphas:\n",
    "    #print 'Alpha:', a\n",
    "    scores = []\n",
    "    for train_index, test_index in kf:\n",
    "        lm = linear_model.Ridge(alpha=a).fit(X.iloc[train_index], y.iloc[train_index])\n",
    "        scores.append(metrics.mean_squared_error(y.iloc[test_index], lm.predict(X.iloc[test_index])))\n",
    "    MSE_Ridge_CV.append(np.mean(scores))\n",
    "\n",
    "            #print lm.coef_\n",
    "        #MSE_Lasso_CV.append(metrics.mean_squared_error(y, lm.predict(X)))\n",
    "\n",
    "index = alphas\n",
    "MSE_Ridge_CV_df = pd.DataFrame({'MSE_Ridge_CV': MSE_Ridge_CV ,'log_alpha': alphas_index })\n",
    "MSE_Ridge_CV_df.plot(x = 'log_alpha',y = 'MSE_Ridge_CV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#MSE is flat up to log_Alpha = 1. log_alpha = 1 results in alpha = 10 (due to its logarithmic scale)\n",
    "lm = linear_model.Ridge(alpha=10)\n",
    "lm.fit(X, y)\n",
    "print zip(lm.coef_,X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Based on Ridge regression model, we are not comfortable to eliminate any variable. Generally, Lasso is much better than Ridge Regression.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling / Standardizing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CreditDataNew = preprocessing.scale(CreditData) #CreditDataNew is now a numpy array\n",
    "CreditDataNew = pd.DataFrame(CreditDataNew)   #We changed CreditDataNew to a dataframe\n",
    "CreditDataNew.columns = CreditData.columns.values  #We renamed columns of CreditDataNew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "CreditDataNew.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = CreditDataNew[listOfAllVariables]\n",
    "del X['Balance']\n",
    "y = CreditDataNew['Balance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kf = cross_validation.KFold(len(CreditDataNew), n_folds = 5, shuffle = True)\n",
    "MSE_Lasso_CV = []\n",
    "alphas = np.logspace(-10, 10, 21)\n",
    "alphas_index = np.linspace(-10,10,21)\n",
    "scores = []\n",
    "for a in alphas:\n",
    "    print 'Alpha:', a\n",
    "    scores = []\n",
    "    for train_index, test_index in kf:\n",
    "        lm = linear_model.Lasso(alpha=a).fit(X.iloc[train_index], y.iloc[train_index])\n",
    "        scores.append(metrics.mean_squared_error(y.iloc[test_index], lm.predict(X.iloc[test_index])))\n",
    "    MSE_Lasso_CV.append(np.mean(scores))\n",
    "\n",
    "\n",
    "\n",
    "index = alphas\n",
    "MSE_Lasso_CV_df = pd.DataFrame({'MSE_Lasso_CV': MSE_Lasso_CV ,'Log_Alphas': alphas_index })\n",
    "MSE_Lasso_CV_df.plot(x = 'Log_Alphas',y = 'MSE_Lasso_CV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lm = linear_model.Lasso(alpha=10**(-2))\n",
    "lm.fit(X, y)\n",
    "print zip(lm.coef_,X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### When you standardize data, then relative magnitude of coefficients are meaningful. Small Coefficients suggest insignificancy of inclusion of that variable in your model. In this case, Income, Limit, Rating and Student_status are considerably more significant than other variables. Among (Income, Limit and Rating) we only choose one due to high colinearity. Therefore, in are final model it is logical to keep (income, Limit, or Rating) + Student stauts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
